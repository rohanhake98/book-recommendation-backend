{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ccab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71fe2467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohan\\Desktop\\book-recommendation-project\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fbc493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_14432\\370617393.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('../data/raw/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv('../data/raw/Books.csv')\n",
    "users = pd.read_csv('../data/raw/Users.csv')\n",
    "ratings = pd.read_csv('../data/raw/Ratings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66f8030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_14432\\3235032442.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('../data/raw/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the three CSV files\n",
    "books = pd.read_csv('../data/raw/Books.csv')\n",
    "users = pd.read_csv('../data/raw/Users.csv')\n",
    "ratings = pd.read_csv('../data/raw/Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020962ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books shape: (271360, 8)\n",
      "Users shape: (278858, 3)\n",
      "Ratings shape: (1149780, 3)\n"
     ]
    }
   ],
   "source": [
    "# Basic info about each dataset\n",
    "print(\"Books shape:\", books.shape)\n",
    "print(\"Users shape:\", users.shape) \n",
    "print(\"Ratings shape:\", ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d775674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BOOKS ---\n",
      "         ISBN                                         Book-Title  \\\n",
      "0  0195153448                                Classical Mythology   \n",
      "1  0002005018                                       Clara Callan   \n",
      "2  0060973129                               Decision in Normandy   \n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4  0393045218                             The Mummies of Urumchi   \n",
      "\n",
      "            Book-Author Year-Of-Publication                   Publisher  \\\n",
      "0    Mark P. O. Morford                2002     Oxford University Press   \n",
      "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
      "2          Carlo D'Este                1991             HarperPerennial   \n",
      "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
      "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
      "\n",
      "                                         Image-URL-S  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-M  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-L  \n",
      "0  http://images.amazon.com/images/P/0195153448.0...  \n",
      "1  http://images.amazon.com/images/P/0002005018.0...  \n",
      "2  http://images.amazon.com/images/P/0060973129.0...  \n",
      "3  http://images.amazon.com/images/P/0374157065.0...  \n",
      "4  http://images.amazon.com/images/P/0393045218.0...  \n",
      "\n",
      "--- USERS ---\n",
      "   User-ID                            Location   Age\n",
      "0        1                  nyc, new york, usa   NaN\n",
      "1        2           stockton, california, usa  18.0\n",
      "2        3     moscow, yukon territory, russia   NaN\n",
      "3        4           porto, v.n.gaia, portugal  17.0\n",
      "4        5  farnborough, hants, united kingdom   NaN\n",
      "\n",
      "--- RATINGS ---\n",
      "   User-ID        ISBN  Book-Rating\n",
      "0   276725  034545104X            0\n",
      "1   276726  0155061224            5\n",
      "2   276727  0446520802            0\n",
      "3   276729  052165615X            3\n",
      "4   276729  0521795028            6\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"\\n--- BOOKS ---\")\n",
    "print(books.head())\n",
    "print(\"\\n--- USERS ---\")\n",
    "print(users.head())\n",
    "print(\"\\n--- RATINGS ---\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "496cf417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books missing values:\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n",
      "\n",
      "Users missing values:\n",
      "User-ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n",
      "\n",
      "Ratings missing values:\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "dtype: int64\n",
      "\n",
      "Books data types:\n",
      "ISBN                   object\n",
      "Book-Title             object\n",
      "Book-Author            object\n",
      "Year-Of-Publication    object\n",
      "Publisher              object\n",
      "Image-URL-S            object\n",
      "Image-URL-M            object\n",
      "Image-URL-L            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Books missing values:\")\n",
    "print(books.isnull().sum())\n",
    "\n",
    "print(\"\\nUsers missing values:\")\n",
    "print(users.isnull().sum())\n",
    "\n",
    "print(\"\\nRatings missing values:\")\n",
    "print(ratings.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nBooks data types:\")\n",
    "print(books.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "844699ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_14432\\2714536943.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  books_clean['Year-Of-Publication'] = pd.to_numeric(books_clean['Year-Of-Publication'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Remove books with missing essential information\n",
    "books_clean = books.dropna(subset=['Book-Title', 'Book-Author'])\n",
    "\n",
    "# Handle year of publication issues\n",
    "books_clean['Year-Of-Publication'] = pd.to_numeric(books_clean['Year-Of-Publication'], errors='coerce')\n",
    "books_clean = books_clean[(books_clean['Year-Of-Publication'] >= 1900) & \n",
    "                         (books_clean['Year-Of-Publication'] <= 2024)]\n",
    "\n",
    "# Clean ISBN (remove duplicates)\n",
    "books_clean = books_clean.drop_duplicates(subset=['ISBN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf605e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ratings: 1149780\n",
      "Explicit ratings: 433671\n",
      "Clean ratings: 378029\n"
     ]
    }
   ],
   "source": [
    "# Filter out implicit ratings (0) for now, focus on explicit ratings (1-10)\n",
    "ratings_explicit = ratings[ratings['Book-Rating'] > 0]\n",
    "\n",
    "# Remove ratings for books that don't exist in our cleaned books dataset\n",
    "valid_isbns = set(books_clean['ISBN'])\n",
    "ratings_clean = ratings_explicit[ratings_explicit['ISBN'].isin(valid_isbns)]\n",
    "\n",
    "print(f\"Original ratings: {len(ratings)}\")\n",
    "print(f\"Explicit ratings: {len(ratings_explicit)}\")\n",
    "print(f\"Clean ratings: {len(ratings_clean)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3e9ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 22383\n",
      "Unique users: 2800\n",
      "Unique books: 529\n"
     ]
    }
   ],
   "source": [
    "# Start with users who have rated at least 20 books\n",
    "user_counts = ratings_clean['User-ID'].value_counts()\n",
    "active_users = user_counts[user_counts >= 20].index\n",
    "\n",
    "# Start with books that have at least 50 ratings\n",
    "book_counts = ratings_clean['ISBN'].value_counts()\n",
    "popular_books = book_counts[book_counts >= 50].index\n",
    "\n",
    "# Create filtered dataset\n",
    "ratings_filtered = ratings_clean[\n",
    "    (ratings_clean['User-ID'].isin(active_users)) &\n",
    "    (ratings_clean['ISBN'].isin(popular_books))\n",
    "]\n",
    "\n",
    "print(f\"Filtered dataset size: {len(ratings_filtered)}\")\n",
    "print(f\"Unique users: {ratings_filtered['User-ID'].nunique()}\")\n",
    "print(f\"Unique books: {ratings_filtered['ISBN'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6939cbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-item matrix shape: (2800, 529)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create pivot table (user-item matrix)\n",
    "user_item_matrix = ratings_filtered.pivot(\n",
    "    index='User-ID', \n",
    "    columns='ISBN', \n",
    "    values='Book-Rating'\n",
    ").fillna(0)\n",
    "\n",
    "print(\"User-item matrix shape:\", user_item_matrix.shape)\n",
    "\n",
    "# Convert to sparse matrix for memory efficiency\n",
    "user_item_sparse = csr_matrix(user_item_matrix.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb309f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar books: [('0316666009', '1st to Die: A Novel', np.float64(0.12776347624027865)), ('1844262553', 'Free', np.float64(0.1216910871472255)), ('080411109X', 'The Hundred Secret Senses', np.float64(0.1104880440386104)), ('0679745203', 'The English Patient', np.float64(0.10085645518789128)), ('0316096199', 'Lucky : A Memoir', np.float64(0.10007686644145722))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate item-item similarity\n",
    "item_similarity = cosine_similarity(user_item_matrix.T)\n",
    "item_similarity_df = pd.DataFrame(\n",
    "    item_similarity,\n",
    "    index=user_item_matrix.columns,\n",
    "    columns=user_item_matrix.columns\n",
    ")\n",
    "\n",
    "def get_similar_books(isbn, top_n=5):\n",
    "    \"\"\"Get top N similar books for a given ISBN\"\"\"\n",
    "    if isbn not in item_similarity_df.index:\n",
    "        return \"Book not found\"\n",
    "    \n",
    "    similar_scores = item_similarity_df[isbn].sort_values(ascending=False)\n",
    "    similar_books = similar_scores[1:top_n+1]  # Exclude the book itself\n",
    "    \n",
    "    # Get book titles\n",
    "    book_titles = []\n",
    "    for book_isbn in similar_books.index:\n",
    "        title = books_clean[books_clean['ISBN'] == book_isbn]['Book-Title'].iloc[0]\n",
    "        book_titles.append((book_isbn, title, similar_scores[book_isbn]))\n",
    "    \n",
    "    return book_titles\n",
    "\n",
    "# Test the function\n",
    "sample_isbn = ratings_filtered['ISBN'].iloc[0]\n",
    "similar_books = get_similar_books(sample_isbn)\n",
    "print(\"Similar books:\", similar_books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af6979ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user: [('1844262553', 'Free', 'Paul Vincent', np.float64(6.541812050461187)), ('0553280341', 'B Is for Burglar (Kinsey Millhone Mysteries (Paperback))', 'Sue Grafton', np.float64(3.958675600877975)), ('0671001795', 'Two for the Dough', 'Janet Evanovich', np.float64(3.9380563261749284)), ('0449219461', 'H Is for Homicide (Kinsey Millhone Mysteries (Paperback))', 'Sue Grafton', np.float64(3.3935612615935176)), ('1400031354', 'Tears of the Giraffe (No.1 Ladies Detective Agency)', 'Alexander McCall Smith', np.float64(3.2184590748727517))]\n"
     ]
    }
   ],
   "source": [
    "def recommend_books_for_user(user_id, top_n=5):\n",
    "    \"\"\"Recommend books for a specific user\"\"\"\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return \"User not found\"\n",
    "    \n",
    "    # Get books rated by the user\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "    rated_books = user_ratings[user_ratings > 0].index\n",
    "    \n",
    "    # Calculate recommendations based on similar books\n",
    "    recommendations = {}\n",
    "    \n",
    "    for book_isbn in rated_books:\n",
    "        user_rating = user_ratings[book_isbn]\n",
    "        similar_books = get_similar_books(book_isbn, 10)\n",
    "        \n",
    "        for sim_isbn, title, similarity in similar_books:\n",
    "            if sim_isbn not in rated_books:  # Don't recommend already rated books\n",
    "                score = user_rating * similarity\n",
    "                if sim_isbn in recommendations:\n",
    "                    recommendations[sim_isbn] += score\n",
    "                else:\n",
    "                    recommendations[sim_isbn] = score\n",
    "    \n",
    "    # Sort and get top N\n",
    "    top_recommendations = sorted(recommendations.items(), \n",
    "                               key=lambda x: x[1], \n",
    "                               reverse=True)[:top_n]\n",
    "    \n",
    "    # Get book titles\n",
    "    final_recommendations = []\n",
    "    for isbn, score in top_recommendations:\n",
    "        title = books_clean[books_clean['ISBN'] == isbn]['Book-Title'].iloc[0]\n",
    "        author = books_clean[books_clean['ISBN'] == isbn]['Book-Author'].iloc[0]\n",
    "        final_recommendations.append((isbn, title, author, score))\n",
    "    \n",
    "    return final_recommendations\n",
    "\n",
    "# Test recommendations\n",
    "sample_user = ratings_filtered['User-ID'].iloc[0]\n",
    "user_recommendations = recommend_books_for_user(sample_user)\n",
    "print(\"Recommendations for user:\", user_recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5b9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save processed data and similarity matrix\n",
    "with open('models/item_similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(item_similarity_df, f)\n",
    "\n",
    "with open('models/user_item_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(user_item_matrix, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76345e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save processed data and similarity matrix\n",
    "with open('models/item_similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(item_similarity_df, f)\n",
    "\n",
    "with open('models/user_item_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(user_item_matrix, f)\n",
    "\n",
    "with open('models/books_clean.pkl', 'wb') as f:\n",
    "    pickle.dump(books_clean, f)\n",
    "\n",
    "print(\"Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c1569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_rec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
